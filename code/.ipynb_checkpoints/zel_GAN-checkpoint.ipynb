{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# Image data and layers pacakges\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D, MaxPool2D, Rescaling\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "# Losses and Optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Base model class to subclass for training step\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load images from directory\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "# For callbacks and checkpoints\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.train import Checkpoint\n",
    "# Extra\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\GANs\\\\zelda_gan\\\\code\")\n",
    "resize_path = \"..\\\\resized_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 40\n",
    "img_width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_images(in_dir, img_height, img_width, batch_size, save_dir):\n",
    "    norm = lambda x: x.astype(\"float32\")/255\n",
    "    dg = ImageDataGenerator(preprocessing_function = img_norm, zoom_range = 0.25, \n",
    "                                  horizontal_flip = True, rotation_range = 0.05)\n",
    "    x_train = dg.flow_from_directory(in_dir,\n",
    "                                            target_size = (img_height, img_width),\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = True,\n",
    "                                            save_to_dir = save_dir,\n",
    "                                            classes = None,\n",
    "                                            class_mode = None,\n",
    "                                            subset = \"training\")\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2340 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_norm = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = image_dataset_from_directory(resize_path, \n",
    "                                       labels = None, \n",
    "                                       color_mode = 'grayscale', \n",
    "                                       image_size = (img_height , img_width),\n",
    "                                       batch_size = batch_size, \n",
    "                                       shuffle = True)\n",
    "train_ds = train_ds.map(img_norm)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generative NN\n",
    "def build_gen_nn():\n",
    "    # Initialize Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Takes in random values and reshape it to 7x7x64\n",
    "    model.add(Dense(20*15*128, input_dim = 64))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Reshape((20, 15, 128)))\n",
    "\n",
    "    # Effectively doubles the size of previous layer\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "\n",
    "    # Second Upsampling block\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, 5, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    \n",
    "        \n",
    "    # Down Sample\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(256, 5, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    \n",
    "    # Normal Convolutional Block\n",
    "    model.add(Conv2D(256, 4, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    \n",
    "    # Normal Convolutional Block\n",
    "    model.add(Conv2D(512, 4, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(512, 4, padding = \"same\"))\n",
    "    model.add(LeakyReLU(.2))\n",
    "\n",
    "\n",
    "    # Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 4, padding = 'same', activation = \"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_disc_nn():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 5, input_shape = (40,30,1)))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Conv2D(512, 5))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Conv2D(512, 5))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    # Flatten then pass to a dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ZelGAN(Model):\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # pass args and kwards to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for two models\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.transformation = Sequential([\n",
    "  RandomFlip(\"horizontal_and_vertical\"),\n",
    "  RandomRotation(0.2),\n",
    "  RandomZoom(height_factor=(-0.1, 0.1), width_factor = (-0.1, 0.1))\n",
    "])\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def compile(self, gen_opt, disc_opt, gen_loss, disc_loss, *args, **kwargs):\n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "        # Create attributes for losses and optimizers\n",
    "        self.gen_opt = gen_opt\n",
    "        self.disc_opt = disc_opt\n",
    "        self.gen_loss = gen_loss\n",
    "        self.disc_loss = disc_loss\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        # Get the data\n",
    "        real_images = self.transformation(batch)\n",
    "        gen_images = self.generator(tf.random.normal((32, 64, 1), 0, 2), training = False)\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # Pass the real and generated images to the discriminator\n",
    "            yhat_real = self.discriminator(real_images, training = True)\n",
    "            yhat_gen = self.discriminator(gen_images, training = True)\n",
    "            yhat_all = tf.concat([yhat_real, yhat_gen], axis = 0)\n",
    "\n",
    "            # Creat labels for real and generated images\n",
    "            y_all = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_gen)], axis = 0)\n",
    "\n",
    "            # Add some noise to the TRUE outputs\n",
    "            noise_real = .1 * tf.random.normal(tf.shape(yhat_real), 0, 2)\n",
    "            noise_gen = -.1 * tf.random.normal(tf.shape(yhat_gen), 0, 2)\n",
    "            y_all += tf.concat([noise_real, noise_gen], axis = 0)\n",
    "\n",
    "            # Calculate loss\n",
    "            total_disc_loss = self.disc_loss(y_all, yhat_all)\n",
    "\n",
    "        # Apply backprop\n",
    "        disc_grad = disc_tape.gradient(total_disc_loss, self.discriminator.trainable_variables)\n",
    "        self.disc_opt.apply_gradients(zip(disc_grad, self.discriminator.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((64, 64, 1), 0, 2), training = True)\n",
    "            \n",
    "            # Create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training = False)\n",
    "            \n",
    "            # Calculate Loss\n",
    "            total_gen_loss = self.gen_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "            \n",
    "        # Apply Backprop\n",
    "        gen_grad = gen_tape.gradient(total_gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_opt.apply_gradients(zip(gen_grad, self.generator.trainable_variables))\n",
    "        \n",
    "        \n",
    "\n",
    "        return {\"disc_loss\" : total_disc_loss, \"gen_loss\" : total_gen_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Networks\n",
    "generator = build_gen_nn()\n",
    "discriminator = build_disc_nn()\n",
    "\n",
    "# Set up Losses and Optimizers\n",
    "gen_opt = Adam(learning_rate = .000005, beta_1=0.8, clipvalue=1.0)\n",
    "disc_opt = Adam(learning_rate = .0000005, beta_1=0.8, clipvalue=1.0)\n",
    "gen_loss = BinaryCrossentropy()\n",
    "disc_loss = BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Zelda = ZelGAN(generator, discriminator)\n",
    "Zelda.compile(gen_opt, disc_opt, gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img = 1, latent_dim = 64):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        random_latent_vectors = tf.random.normal((self.num_img, self.latent_dim, 1), 0, 2)\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join(\"..\\\\progress_images\", f\"generated_img_{epoch}_{i}.png\"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Zelda.generator.load_weights('..//saves//generator_norm.h5')\n",
    "#Zelda.discriminator.load_weights('..//saves//discriminator_norm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      " 6/74 [=>............................] - ETA: 1:15 - disc_loss: 0.6922 - gen_loss: 0.6941WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4438s vs `on_train_batch_end` time: 0.6689s). Check your callbacks.\n",
      "10/74 [===>..........................] - ETA: 1:11 - disc_loss: 0.6928 - gen_loss: 0.6942"
     ]
    }
   ],
   "source": [
    "hist = Zelda.fit(train_ds, epochs = 1024, callbacks = [ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Zelda.generator.save('..//saves//generator_norm.h5')\n",
    "Zelda.discriminator.save('..//saves//discriminator_norm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_latent_vectors = tf.random.normal((50, 64, 1))\n",
    "#generated_images = Zelda.generator(random_latent_vectors)\n",
    "#generated_images *= 255\n",
    "#generated_images.numpy()\n",
    "#for i in range(50):\n",
    "#    img = array_to_img(generated_images[i])\n",
    "#    img.save(os.path.join(\"..\\\\progress_images\", f\"generated_img_{i}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
